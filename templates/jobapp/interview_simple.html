{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interview - {{ candidate_name }}</title>
    <link rel="stylesheet" href="{% static 'css/professional-interview.css' %}">
    <style>
        body {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0;
            padding: 0;
            height: 100vh;
            overflow: hidden;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            height: 100vh;
            display: flex;
            flex-direction: column;
            padding: 20px;
        }
        .header {
            text-align: center;
            padding: 10px 0;
            border-bottom: 1px solid rgba(255,255,255,0.1);
            margin-bottom: 15px;
        }
        .header h1 {
            font-size: 1.4rem;
            font-weight: 300;
            margin: 0;
            opacity: 0.9;
        }
        .video-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            height: 55vh;
            margin-bottom: 15px;
        }
        .video-box {
            background: rgba(255,255,255,0.1);
            backdrop-filter: blur(20px);
            border-radius: 20px;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            border: 1px solid rgba(255,255,255,0.2);
            transition: all 0.3s ease;
        }
        .ai-avatar-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        .ai-avatar {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            background: linear-gradient(45deg, #4facfe 0%, #00f2fe 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            margin-bottom: 10px;
        }
        .ai-avatar::before {
            content: '';
            position: absolute;
            width: 100%;
            height: 100%;
            border-radius: 50%;
            background: linear-gradient(45deg, #4facfe 0%, #00f2fe 100%);
            animation: siri-pulse 2s ease-in-out infinite;
            z-index: -1;
        }
        .ai-avatar-icon {
            font-size: 1.8rem;
            color: white;
        }
        .ai-speaking {
            border: 2px solid transparent;
            background: linear-gradient(45deg, #4facfe, #00f2fe, #4facfe, #00f2fe) border-box;
            background-clip: padding-box;
            animation: gradient-border 2s ease-in-out infinite;
        }
        .ai-speaking .ai-avatar {
            background: linear-gradient(45deg, #4facfe, #00f2fe, #ff6b6b, #4facfe);
            background-size: 300% 300%;
            animation: gradient-flow 1.5s ease-in-out infinite;
        }
        .candidate-speaking {
            border-color: #4caf50 !important;
            box-shadow: 0 0 30px rgba(76, 175, 80, 0.4);
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            border-radius: 12px;
            transform: scaleX(-1);  /* THIS IS THE FIX - Mirrors video like selfie camera */
        }
        .participant-name {
            position: absolute;
            bottom: 20px;
            left: 20px;
            background: rgba(0,0,0,0.6);
            backdrop-filter: blur(10px);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 500;
        }
        .ai-name {
            color: white;
            font-size: 1.1rem;
            font-weight: 300;
            opacity: 0.9;
        }

         /* FIXED: Timer in top-right corner, separate from candidate name */
        .timer-overlay {
            position: absolute;
            top: 16px;
            right: 16px;
            background: rgba(0,0,0,0.85);
            padding: 10px 18px;
            border-radius: 25px;
            font-size: 20px;
            font-weight: bold;
            backdrop-filter: blur(10px);
            border: 2px solid #4caf50;
            box-shadow: 0 4px 15px rgba(0,0,0,0.4);
        }

        /* NEW: Recording indicator in top-left corner */
        .recording-indicator {
            position: absolute;
            top: 16px;
            left: 16px;
            background: rgba(244, 67, 54, 0.9);  /* Red background */
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 14px;
            font-weight: bold;
            color: white;
            display: flex;
            align-items: center;
            gap: 8px;
            backdrop-filter: blur(10px);
            box-shadow: 0 4px 15px rgba(244, 67, 54, 0.4);
        }
        .recording-dot {
            width: 10px;
            height: 10px;
            background: white;
            border-radius: 50%;
            animation: blink-recording 1.5s ease-in-out infinite;  /* Blinking effect */
        
        }

        @keyframes blink-recording {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
        @keyframes blink-status {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
        .face-detection-status.active {
            background: rgba(76, 175, 80, 0.9) !important;
        }
        .face-detection-status.active .status-dot {
            background: #4caf50 !important;
        }
        .controls {
            position: absolute;
            bottom: 15px;
            right: 15px;
            display: flex;
            gap: 8px;
            align-items: center;
        }
        {% comment %} .btn {
            color: white;
            border: none;
            padding: 10px 12px;       /* ‚Üê More padding for rectangular shape */
            border-radius: 28px;      /* ‚Üê CHANGED: Less rounded (was 50px) */
            font-size: 18px;          /* ‚Üê Slightly larger icon */
            cursor: pointer;
            transition: all 0.3s ease;
            min-width: 45px;          /* ‚Üê Google Meet size */
            height: 45px;             /* ‚Üê Google Meet size */
            display: flex;
            align-items: center;
            justify-content: center;
        } {% endcomment %}
         /* FIXED: Button styling - cleaner backgrounds like Google Meet */
        .btn {
            background: rgba(0,0,0,0.6);
            backdrop-filter: blur(10px);
            color: white;
            border: 1px solid rgba(255,255,255,0.2);
            padding: 6px;
            border-radius: 50%;
            font-size: 0.8rem;
            cursor: pointer;
            transition: all 0.3s ease;
            width: 32px;
            height: 32px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .btn:hover {
            transform: scale(1.05);
            background: rgba(255,255,255,0.3);
            box-shadow: 0 8px 25px rgba(0,0,0,0.2);
        }
        {% comment %} .btn:hover {
            transform: scale(1.05);
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
        } {% endcomment %}
        {% comment %} .btn.mic {
            background: #4caf50;
        } {% endcomment %}
         /* Microphone button - green when active */
        .btn.mic {
            background: rgba(60, 64, 67, 0.95);
        }
        .btn.mic.recording {
            background: #4caf50;
            animation: recording-pulse 1s infinite;
        }
        .btn.mic.disabled {
            background: #666;
            cursor: not-allowed;
            opacity: 0.5;
        }
        {% comment %} .btn.camera {
            background: #2196f3;
        } {% endcomment %}
        {% comment %} .btn.camera.off {
            background: #666;
        } {% endcomment %}
        .btn.end-call {
            background: #f44336;
        }
        {% comment %} .transcript-section {
            background: #303134;
            padding: 20px 25px;
            border-radius: 12px;
            margin: 0 0 15px 0;
            padding-bottom: 120px;  /* CRITICAL: Space for buttons at bottom - prevents overlap */
            flex: 1;
            display: flex;
            flex-direction: column;
            border: 2px solid #444;
            min-height: 120px;  /* ‚Üê CHANGE TO: 150px (50% smaller) */
            max-height: 180px;  /* Added max-height to control size */
            overflow: hidden;
        } {% endcomment %}
         
        .transcript-section {
            background: rgba(255,255,255,0.1);
            backdrop-filter: blur(20px);
            padding: 15px;
            border-radius: 20px;
            margin: 0 0 15px 0;
            border: 1px solid rgba(255,255,255,0.2);
            height: 80px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .conversation-text {
            color: white;
            font-size: 1rem;
            line-height: 1.4;
            text-align: center;
            font-weight: 300;
        }
        .stats {
            display: none;
        }
        .stat {
            background: rgba(255,255,255,0.1);
            backdrop-filter: blur(20px);
            padding: 12px 24px;
            border-radius: 25px;
            font-weight: 500;
            border: 1px solid rgba(255,255,255,0.2);
        }
        .audio-status {
            position: fixed;
            top: 30px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(26, 115, 232, 0.9);
            backdrop-filter: blur(20px);
            color: white;
            padding: 12px 24px;
            border-radius: 25px;
            font-size: 0.9rem;
            font-weight: 500;
            z-index: 1000;
            display: none;
            border: 1px solid rgba(255,255,255,0.2);
        }
        .audio-status.playing {
            display: block;
            background: #ff9800;
            animation: status-pulse 2s ease-in-out infinite;
        }
        .audio-status.listening {
            display: block;
            background: #4caf50;
            animation: status-pulse 2s ease-in-out infinite;
        }
        
        /* Animations */
        @keyframes siri-pulse {
            0% { transform: scale(1); opacity: 0.7; }
            50% { transform: scale(1.1); opacity: 0.9; }
            100% { transform: scale(1); opacity: 0.7; }
        }
        @keyframes gradient-border {
            0%, 100% { box-shadow: 0 0 20px rgba(79, 172, 254, 0.5); }
            50% { box-shadow: 0 0 30px rgba(0, 242, 254, 0.8); }
        }
        @keyframes gradient-flow {
            0% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
            100% { background-position: 0% 50%; }
        }
        @keyframes recording-pulse {
            0%, 100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(76, 175, 80, 0.7); }
            50% { transform: scale(1.05); box-shadow: 0 0 0 10px rgba(76, 175, 80, 0); }
        }
        @keyframes status-pulse {
            0%, 100% { opacity: 0.9; }
            50% { opacity: 1; }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Audio status indicator -->
        <div class="audio-status" id="audioStatus"></div>

        <!-- Professional Header -->
        <div class="header">
            <h1>Interview Session for {{ candidate_name }}</h1>
            <p style="font-size: 1.1rem; margin: 5px 0 0 0; opacity: 0.8; font-weight: 400;">{{ job_title }} by {{ company_name }}</p>
        </div>

        <!-- Hidden stats section -->
        <div class="stats" style="display: none;">
            <div class="stat"><span id="questionCount"></span></div> 
        </div>
        
        
         {% comment %} <div class="stats">
            <div class="stat"> <span id="questionCount"></span></div> 
            <div class="stat">Time: <span id="timer">15:00</span></div> 
        </div>  {% endcomment %}
        
        <div class="video-grid">
            <div class="video-box" id="aiVideoBox">
                <div class="ai-avatar-container">
                    <div class="ai-avatar" id="aiAvatar">
                        <div class="ai-avatar-icon">ü§ñ</div>
                    </div>
                    <div class="ai-name">Sarah - AI Interviewer</div>
                </div>
            </div>
            <div class="video-box" id="candidateVideoBox">
                <video id="userVideo" autoplay muted playsinline></video>

                <!-- NEW: Recording indicator in top-left -->
                <div class="recording-indicator">
                    <div class="recording-dot"></div>
                    <span>REC</span>
                </div>

                <!-- Face Detection Status Indicator -->
                <div class="face-detection-status" id="faceStatus" style="
                    position: absolute;
                    bottom: 60px;
                    left: 16px;
                    background: rgba(244, 67, 54, 0.9);
                    padding: 6px 12px;
                    border-radius: 15px;
                    font-size: 12px;
                    font-weight: bold;
                    color: white;
                    display: flex;
                    align-items: center;
                    gap: 6px;
                    backdrop-filter: blur(10px);
                    transition: all 0.3s ease;
                ">
                    <div class="status-dot" style="
                        width: 8px;
                        height: 8px;
                        background: #ff4444;
                        border-radius: 50%;
                        animation: blink-status 2s ease-in-out infinite;
                    "></div>
                    <span>Face Detection: OFF</span>
                </div>

                <!-- Candidate name at bottom-left -->
                <div class="participant-name">{{ candidate_name|default:"Candidate" }}</div>

                
                <!-- NEW: Timer moved here, positioned on top-right of video -->
                <div class="timer-overlay">
                    <span id="timer">{{ interview.interview_duration_minutes|default:"15" }}:00</span>
                </div>

                <!-- Compact controls in bottom-right -->
                <div class="controls">
                    <button class="btn mic" id="micBtn" onclick="toggleMic()" title="Toggle Microphone" style="display: none;">üé§</button>
                    <button class="btn" onclick="startFaceDetection()" title="Start Face Detection" style="background: #2196f3; padding: 8px 12px; border-radius: 20px; font-size: 12px;">üëÅÔ∏è Face</button>
                    <button class="btn end-call" onclick="endInterview()" title="End Interview" style="padding: 12px 20px; width: auto; border-radius: 25px; font-size: 1rem; font-weight: 500;">End Interview</button>
                </div>
            </div>
        </div>

        <div class="transcript-section">
            <div class="conversation-text" id="conversationArea">
                
            </div>
        </div>


    </div>

    <!-- Audio element for playing interviewer's voice -->
    <audio id="aiAudio" preload="auto"></audio>
    
    <!-- CSRF Token -->
    {% csrf_token %}
    
    <!-- Load typewriter script -->
    <script src="{% static 'js/typewriter-sync.js' %}"></script>
    
    <!-- Load face tracking script -->
    <script src="{% static 'js/face-tracking.js' %}"></script>
    
    <script>
    // Force face tracking initialization
    window.initFaceTracking = function() {
        const video = document.getElementById('userVideo');
        if (video) {
            console.log('üéØ Force initializing face tracking');
            const tracker = new FaceTracker(video);
            tracker.start();
        }
    };
    </script>

    <script>
    // Template data passed from Django
const TEMPLATE_DATA = {
    initialQuestion: `{{ ai_question|escapejs|default:"Welcome to your AI interview! Let's begin." }}`,
    initialAudio: `{{ audio_url|escapejs|safe }}`,
    initialDuration: {{ audio_duration|default:5 }},
    candidateName: `{{ candidate_name|escapejs|default:"Candidate" }}`,
    interviewUuid: `{{ interview.uuid|default:"" }}`,
    hasAudio: {{ has_audio|yesno:"true,false" }},
    csrfToken: `{{ csrf_token }}`
};

// Global variables
let recognition = null;
let isListening = false;
let questionCount = 1;
let timeLeft = {{ interview.interview_duration_minutes|default:"15" }} * 60; // Interview duration in seconds - CRITICAL FOR TIMER
let userStream = null;
let isCameraOn = true;
let collectedText = '';
let speechTimeout = null;
let isProcessingResponse = false;
let isInterviewerSpeaking = false;
let interviewCompleted = false;
let audioEndedTimeout = null;
let isInitialized = false;

// UI Elements
const conversationArea = document.getElementById('conversationArea');
const audioStatus = document.getElementById('audioStatus');
const micBtn = document.getElementById('micBtn');
const cameraBtn = document.getElementById('cameraBtn');

// Simple logging for debugging
function log(message) {
    console.log(`[${new Date().toLocaleTimeString()}] ${message}`);
}

log('AI Interview System Starting...');

// Initialize camera and microphone
async function initCamera() {
    try {
        log('Requesting camera and microphone permissions...');
        
        userStream = await navigator.mediaDevices.getUserMedia({ 
            video: {
                width: { ideal: 1280 },
                height: { ideal: 720 },
                facingMode: 'user'
            }, 
            audio: {
                echoCancellation: true,
                noiseSuppression: false,  // Turn off - can interfere
                autoGainControl: false,   // Turn off - can distort
                sampleRate: 16000,        // Optimal for Whisper
                channelCount: 1           // Mono is fine for speech
            }
        });
        
        const videoElement = document.getElementById('userVideo');
        videoElement.srcObject = userStream;
        
        log('Camera and microphone access granted');
        return true;
        
    } catch (error) {
        log(`Media access error: ${error.message}`);
        conversationArea.innerHTML = 
            `<div style="color: #f44336; padding: 20px;">Please allow camera and microphone access, then refresh this page.</div>`;
        return false;
    }
}

// Initialize speech recognition
function initSpeech() {
    log('Initializing speech recognition...');
    
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        log('Web Speech API not supported - will use Whisper ASR fallback');
        conversationArea.innerHTML = 
            `<div style="color: #4caf50; padding: 20px;">Using server-side speech recognition. Click microphone to record audio.</div>`;
        // Enable Whisper mode
        window.useWhisperASR = true;
        return true; // Continue with Whisper mode
    }
    
    window.useWhisperASR = false; // Use Web Speech API
    
    try {
        const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
        recognition = new SpeechRecognition();
        
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';
        recognition.maxAlternatives = 1;
        
        recognition.onstart = function() {
            isListening = true;
            micBtn.classList.add('recording');
            document.getElementById('candidateVideoBox').classList.add('candidate-speaking');
            log('Speech recognition started');
        };
        
        recognition.onend = function() {
            document.getElementById('candidateVideoBox').classList.remove('candidate-speaking');
            log('Speech recognition ended');
            
            // Auto-restart if still listening and not during interviewer speech
            if (isListening && !interviewCompleted && !isInterviewerSpeaking) {
                setTimeout(() => {
                    try {
                        if (recognition && isListening) {
                            recognition.start();
                            log('Speech recognition restarted');
                        }
                    } catch (e) {
                        log(`Could not restart recognition: ${e.message}`);
                    }
                }, 100);
            }
        };
        
        recognition.onerror = function(event) {
            log(`Speech recognition error: ${event.error}`);
            document.getElementById('candidateVideoBox').classList.remove('candidate-speaking');
            
            // Add specific error handling for different error types
            if (event.error === 'network') {
                // Switch to Whisper mode
                window.useWhisperASR = true;
                initWhisperRecording();
                conversationArea.innerHTML = 
                    `<div style="color: #4caf50; padding: 20px;">Switched to server-side speech recognition due to network issues.</div>`;
            } else if (event.error === 'not-allowed') {
                conversationArea.innerHTML = 
                    `<div style="color: #4caf50; padding: 20px;">Microphone access denied. Please allow microphone access and refresh.</div>`;
            } else if (event.error === 'no-speech') {
                log('No speech detected, continuing...');
            } else {
                log(`Unhandled speech error: ${event.error}`);
            }
        };
        
        recognition.onresult = function(event) {
            let interimTranscript = '';
            let finalTranscript = '';
            
            for (let i = event.resultIndex; i < event.results.length; i++) {
                const transcript = event.results[i][0].transcript;
                if (event.results[i].isFinal) {
                    finalTranscript += transcript;
                } else {
                    interimTranscript += transcript;
                }
            }
            
            // Only process speech when candidate can speak
            if (!isInterviewerSpeaking && !isProcessingResponse && !interviewCompleted) {
                
                // Show live transcription
                const displayText = collectedText + finalTranscript + 
                    (interimTranscript ? `<span style="opacity: 0.7; font-style: italic; color: #90a4ae;">${interimTranscript}</span>` : '');
                
                if (displayText.trim()) {
                    conversationArea.innerHTML = 
                        `<div style="color: #81c784; font-style: italic;">"${displayText}"</div>`;
                }
            
                if (finalTranscript.trim()) {
                    collectedText += finalTranscript;
                    log(`Speech captured: "${finalTranscript}"`);
                
                    // Clear existing timeout
                    if (speechTimeout) {
                        clearTimeout(speechTimeout);
                    }
                
                    // Auto-submit after pause - increased timeout for better speech capture
                    speechTimeout = setTimeout(() => {
                        if (collectedText.trim() && !isProcessingResponse && !isInterviewerSpeaking && !interviewCompleted) {
                            autoSubmitResponse();
                        }
                    }, 5000); // Increased from 3000 to 5000ms
                }
            }
        };
        
        log('Speech recognition initialized successfully');
        return true;
        
    } catch (error) {
        log(`Error initializing speech: ${error.message}`);
        return false;
    }
}

// Start microphone
function startMicrophone() {
    if (recognition && !isListening && !interviewCompleted && !isInterviewerSpeaking) {
        try {
            isListening = true;
            recognition.start();
            micBtn.classList.add('recording');
            log('Microphone started - ready to listen');
        } catch (e) {
            log(`Failed to start microphone: ${e.message}`);
            if (e.name === 'InvalidStateError') {
                isListening = true; // Already running
            } else {
                isListening = false;
                micBtn.classList.remove('recording');
            }
        }
    }
}

// Stop microphone
function stopMicrophone() {
    if (recognition && isListening) {
        try {
            recognition.stop();
            isListening = false;
            micBtn.classList.remove('recording');
            log('Microphone stopped');
        } catch (e) {
            log(`Error stopping microphone: ${e.message}`);
        }
    }
}

// Auto-submit response
function autoSubmitResponse() {
    if (isProcessingResponse || isInterviewerSpeaking || !collectedText.trim() || interviewCompleted) {
        return;
    }
    
    log(`Submitting response (Time remaining: ${timeLeft}s): "${collectedText.substring(0, 50)}..."`);
    isProcessingResponse = true;
    
    if (speechTimeout) {
        clearTimeout(speechTimeout);
        speechTimeout = null;
    }
    
    const responseText = collectedText.trim();
    collectedText = '';
    
    // Stop listening during processing
    stopMicrophone();
    
    conversationArea.innerHTML = 
        `<div style="opacity: 0.7; font-style: italic;">Processing your response...</div>`;
    
    sendResponse(responseText).finally(() => {
        isProcessingResponse = false;
    });
}

// Send response to server - FIXED TO ALWAYS INCLUDE TIME
async function sendResponse(text) {
    try {
        log(`Sending response to server with ${timeLeft}s remaining`);
        
        const response = await fetch(window.location.href, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/x-www-form-urlencoded',
                'X-CSRFToken': TEMPLATE_DATA.csrfToken,
            },
            body: new URLSearchParams({ 
                text: text,
                time_remaining: timeLeft  // CRITICAL: Send current time
            })
        });
        
        if (!response.ok) {
            throw new Error(`Server error: ${response.status}`);
        }
        
        const data = await response.json();
        log('Server response received');
        
        if (data.success) {
            questionCount = data.question_count || questionCount + 1;
            document.getElementById('questionCount').textContent = `${questionCount}/‚àû`;  // Show infinity symbol
            
            setTimeout(() => {
                showCurrentQuestion(data.response, data.audio, data.audio_duration);
            }, 100); //Reduced from 500ms to 100ms
            
            if (data.interview_completed || data.is_final) {
                log('Interview completed');
                interviewCompleted = true;
            }
        } else {
            log('Server returned error');
            conversationArea.innerHTML = 
                `<div style="color: #f44336; padding: 20px;">Error processing response. Please try again.</div>`;
            enableCandidateResponse();
        }
    } catch (error) {
        log(`Network error: ${error.message}`);
        conversationArea.innerHTML = 
            `<div style="color: #f44336; padding: 20px;">Network error. Please check connection and try again.</div>`;
        enableCandidateResponse();
    }
}

// Show current question
function showCurrentQuestion(question, audioUrl = null, audioDuration = null) {
    log(`Showing question: ${question.substring(0, 50)}...`);
    
    conversationArea.innerHTML = '';
    isProcessingResponse = true;
    isInterviewerSpeaking = true;
    
    // Stop speech recognition during interviewer speaking
    stopMicrophone();
    
    micBtn.classList.add('disabled');
    document.getElementById('aiVideoBox').classList.add('ai-speaking');
    
    if (audioEndedTimeout) {
        clearTimeout(audioEndedTimeout);
        audioEndedTimeout = null;
    }
    
    // Check for valid audio
    const hasValidAudio = audioUrl && 
                          audioUrl.trim() !== '' && 
                          audioUrl !== 'None' && 
                          audioDuration && 
                          audioDuration > 0;
    
    if (hasValidAudio) {
        log('Playing audio with question');
        
        audioStatus.className = 'audio-status playing';
        audioStatus.textContent = 'Interviewer speaking - Please listen';
        audioStatus.style.display = 'block';
        
        const audio = document.getElementById('aiAudio');
        audio.pause();
        audio.currentTime = 0;
        audio.src = audioUrl.startsWith('/media/') ? audioUrl : `/media/${audioUrl.replace(/^\/+/, '')}`;
        audio.volume = 0.8;
        
        const onCanPlay = () => {
            audio.removeEventListener('canplaythrough', onCanPlay);
            audio.play().then(() => {
                log('Audio playing');
                if (window.TypewriterSync) {
                    window.TypewriterSync.start(conversationArea, question, audio, audioDuration);
                } else {
                    startFallbackTypewriter(conversationArea, question, audioDuration);
                }
            }).catch(error => {
                log(`Audio play failed: ${error.message}`);
                startFallbackTypewriter(conversationArea, question);
                setTimeout(() => enableCandidateResponse(), audioDuration * 1000 || 3000);
            });
        };
        
        const onAudioEnded = () => {
            log('Audio playback completed');
            audio.removeEventListener('ended', onAudioEnded);
            setTimeout(() => enableCandidateResponse(), 1000);
        };
        
        audio.addEventListener('canplaythrough', onCanPlay);
        audio.addEventListener('ended', onAudioEnded);
        
        // Fallback timeout
        audioEndedTimeout = setTimeout(() => {
            if (isInterviewerSpeaking) {
                log('Audio timeout - enabling microphone');
                enableCandidateResponse();
            }
        }, (audioDuration + 3) * 1000);
        
        audio.load();
        
    } else {
        log('No audio, showing text only');
        audioStatus.style.display = 'none';
        
        if (window.TypewriterSync) {
            window.TypewriterSync.createTextOnly(conversationArea, question, { fast: false }).then(() => {
                setTimeout(() => enableCandidateResponse(), 1000);
            });
        } else {
            startFallbackTypewriter(conversationArea, question);
        }
    }
}

function startFallbackTypewriter(element, question, audioDuration = null) {
    log('Using fallback typewriter');
    let index = 0;
    const targetDuration = audioDuration ? audioDuration * 1000 : Math.min(question.length * 60, 6000);
    const charDelay = Math.max(30, Math.min(100, targetDuration / question.length));
    
    const typeChar = () => {
        if (index < question.length) {
            element.textContent += question.charAt(index);
            index++;
            setTimeout(typeChar, charDelay);
        } else {
            if (!audioDuration) {
                setTimeout(() => enableCandidateResponse(), 1000);
            }
        }
    };
    typeChar();
}

// Enable candidate response - CRITICAL FUNCTION
function enableCandidateResponse() {
    log('Enabling candidate response - MICROPHONE NOW ACTIVE');
    
    isInterviewerSpeaking = false;
    isProcessingResponse = false;
    
    micBtn.classList.remove('disabled');
    document.getElementById('aiVideoBox').classList.remove('ai-speaking');
    
    audioStatus.className = 'audio-status listening';
    audioStatus.textContent = 'üé§ Your turn - Start speaking';
    audioStatus.style.display = 'block';
    
    setTimeout(() => {
        audioStatus.style.display = 'none';
    }, 4000);
    
    if (audioEndedTimeout) {
        clearTimeout(audioEndedTimeout);
        audioEndedTimeout = null;
    }
    
    // Clear collected text
    collectedText = '';
    
    // Start microphone immediately
    setTimeout(() => {
        if (!interviewCompleted && recognition) {
            startMicrophone();
            log('‚úì Microphone enabled and listening for candidate response');
        }
    }, 100); // Reduced from 500ms to 100ms
}

// Whisper ASR variables
let mediaRecorder = null;
let audioChunks = [];
let isRecording = false;

// Initialize Whisper recording
function initWhisperRecording() {
    if (!userStream) {
        log('No audio stream available for Whisper recording');
        return false;
    }
    
    try {
        mediaRecorder = new MediaRecorder(userStream, { mimeType: 'audio/webm' });
        
        mediaRecorder.ondataavailable = event => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };
        
        mediaRecorder.onstop = async () => {
            if (audioChunks.length > 0) {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                await sendWhisperAudio(audioBlob);
            }
            audioChunks = [];
        };
        
        log('Whisper recording initialized');
        return true;
    } catch (error) {
        log(`Whisper recording init failed: ${error.message}`);
        return false;
    }
}

// Send audio to Whisper ASR
async function sendWhisperAudio(audioBlob) {
    try {
        log('Sending audio to Whisper ASR...');
        
        const formData = new FormData();
        formData.append('audio', audioBlob, 'response.webm');
        formData.append('time_remaining', timeLeft);
        
        conversationArea.innerHTML = 
            `<div style="opacity: 0.7; font-style: italic;">Processing your speech...</div>`;
        
        const response = await fetch(window.location.href, {
            method: 'POST',
            body: formData,
            headers: {
                'X-CSRFToken': TEMPLATE_DATA.csrfToken
            }
        });
        
        const data = await response.json();
        
        if (data.success) {
            log(`Whisper transcription: ${data.transcribed_text || 'N/A'}`);
            displayAIResponse(data);
        } else {
            log(`Whisper ASR failed: ${data.error}`);
            conversationArea.innerHTML = 
                `<div style="color: #f44336; padding: 20px;">Speech recognition failed: ${data.error}</div>`;
            enableCandidateResponse();
        }
        
    } catch (error) {
        log(`Whisper upload failed: ${error.message}`);
        conversationArea.innerHTML = 
            `<div style="color: #f44336; padding: 20px;">Network error. Please try again.</div>`;
        enableCandidateResponse();
    }
}

// Start Whisper recording
function startWhisperRecording() {
    if (!mediaRecorder || isRecording) return;
    
    try {
        audioChunks = [];
        mediaRecorder.start();
        isRecording = true;
        
        micBtn.classList.add('recording');
        document.getElementById('candidateVideoBox').classList.add('candidate-speaking');
        
        conversationArea.innerHTML = 
            `<div style="color: #81c784; font-style: italic;">Recording... Click microphone again to stop</div>`;
        
        log('Whisper recording started');
    } catch (error) {
        log(`Failed to start Whisper recording: ${error.message}`);
    }
}

// Stop Whisper recording
function stopWhisperRecording() {
    if (!mediaRecorder || !isRecording) return;
    
    try {
        mediaRecorder.stop();
        isRecording = false;
        
        micBtn.classList.remove('recording');
        document.getElementById('candidateVideoBox').classList.remove('candidate-speaking');
        
        log('Whisper recording stopped');
    } catch (error) {
        log(`Failed to stop Whisper recording: ${error.message}`);
    }
}

// Toggle microphone (updated for Whisper support)
function toggleMic() {
    if (interviewCompleted) return;
    
    if (isInterviewerSpeaking) {
        alert('Please wait for the interviewer to finish speaking.');
        return;
    }
    
    // Use Whisper ASR mode
    if (window.useWhisperASR) {
        if (isRecording) {
            log('Stopping Whisper recording');
            stopWhisperRecording();
        } else {
            log('Starting Whisper recording');
            startWhisperRecording();
        }
        return;
    }
    
    // Use Web Speech API mode (existing code)
    if (!recognition) return;
    
    if (isListening) {
        log('Manually stopping microphone');
        stopMicrophone();
        
        if (collectedText.trim()) {
            autoSubmitResponse();
        }
    } else {
        log('Manually starting microphone');
        collectedText = '';
        startMicrophone();
    }
}

// Toggle camera
{% comment %} function toggleCamera() {
    if (!userStream) return;
    
    const videoTracks = userStream.getVideoTracks();
    isCameraOn = !isCameraOn;
    
    videoTracks.forEach(track => {
        track.enabled = isCameraOn;
    });
    
    if (isCameraOn) {
        cameraBtn.classList.remove('off');
        cameraBtn.title = 'Camera ON - Click to turn off';
    } else {
        cameraBtn.classList.add('off');
        cameraBtn.title = 'Camera OFF - Click to turn on';
    }
    
    log(`Camera ${isCameraOn ? 'enabled' : 'disabled'}`);
} {% endcomment %}

// Manual face detection start
function startFaceDetection() {
    console.log('üîÑ Manual face detection start');
    const video = document.getElementById('userVideo');
    
    if (!video) {
        alert('Video not found');
        return;
    }
    
    if (video.videoWidth === 0) {
        alert('Camera not ready yet');
        return;
    }
    
    // Force create new tracker
    window.globalFaceTracker = new FaceTracker(video);
    window.globalFaceTracker.start();
    
    console.log('‚úÖ Face tracker manually started');
}

// End interview
function endInterview() {
    if (confirm('Are you sure you want to end the interview?')) {
        log('Interview ended by candidate');
        interviewCompleted = true;
        
        stopMicrophone();
        
        // Stop camera and microphone
        if (userStream) {
            userStream.getTracks().forEach(track => {
                track.stop();
                log(`${track.kind} track stopped`);
            });
        }

        // Hide all interview elements
        document.querySelector('.video-grid').style.display = 'none';
        document.querySelector('.transcript-section').style.display = 'none';
        document.querySelector('.stats').style.display = 'none';
        document.getElementById('micBtn').style.display = 'none';

                // Show large full-page completion message
        document.body.innerHTML = `
            <div style="
                display: flex;
                flex-direction: column;
                justify-content: center;
                align-items: center;
                height: 100vh;
                background: #202124;
                color: white;
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                text-align: center;
                padding: 40px;
            ">
                <div style="max-width: 800px;">
                    <h1 style="
                        font-size: 48px;
                        margin-bottom: 30px;
                        color: #4caf50;
                        font-weight: bold;
                    ">Interview Ended</h1>
                    
                    <p style="
                        font-size: 28px;
                        line-height: 1.6;
                        margin-bottom: 20px;
                        color: #e0e0e0;
                    ">Thank you for participating in the AI interview.</p>
                    
                    <p style="
                        font-size: 24px;
                        color: #b0b0b0;
                        margin-bottom: 50px;
                    ">You can close this window now.</p>
                </div>
                
                {% comment %} <button onclick="window.close()" style="
                    background: #f44336;
                    color: white;
                    border: none;
                    padding: 18px 40px;
                    border-radius: 50px;
                    font-size: 20px;
                    cursor: pointer;
                    transition: all 0.3s ease;
                    margin-top: 30px;
                " onmouseover="this.style.transform='scale(1.05)'" 
                   onmouseout="this.style.transform='scale(1)'">
                    üìû Close Interview
                </button> {% endcomment %}
            </div>
        `;
    }
}
        


// Timer - UPDATED TO SHOW WHEN TIME IS LOW
function updateTimer() {
    if (interviewCompleted) return;
    
    const minutes = Math.floor(timeLeft / 60);
    const seconds = timeLeft % 60;
    const timerElement = document.getElementById('timer');
    timerElement.textContent = `${minutes}:${seconds.toString().padStart(2, '0')}`;
    
    // Change color when time is running low
    if (timeLeft <= 120) {  // Last 2 minutes
        timerElement.style.color = '#ff9800';
    }
    if (timeLeft <= 30) {  // Last 30 seconds
        timerElement.style.color = '#f44336';
    }
    
    if (timeLeft <= 0) {
        log('Time expired');
        interviewCompleted = true;
        stopMicrophone();
        
        // Stop camera and microphone
        if (userStream) {
            userStream.getTracks().forEach(track => {
                track.stop();
                log(`${track.kind} track stopped`);
            });
        }

        // Hide video boxes, transcript, and mic button
        document.querySelector('.video-grid').style.display = 'none';
        document.querySelector('.transcript-section').style.display = 'none';
        document.querySelector('.stats').style.display = 'none';
        document.getElementById('micBtn').style.display = 'none';


        // Show large full-page completion message
        document.body.innerHTML = `
            <div style="
                display: flex;
                flex-direction: column;
                justify-content: center;
                align-items: center;
                height: 100vh;
                background: #202124;
                color: white;
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                text-align: center;
                padding: 40px;
            ">
                <div style="max-width: 800px;">
                    <h1 style="
                        font-size: 48px;
                        margin-bottom: 30px;
                        color: #4caf50;
                        font-weight: bold;
                    ">Interview Time Completed</h1>
                    
                    <p style="
                        font-size: 28px;
                        line-height: 1.6;
                        margin-bottom: 20px;
                        color: #e0e0e0;
                    ">Thank you for participating in the AI interview.</p>
                    
                    <p style="
                        font-size: 24px;
                        color: #b0b0b0;
                        margin-bottom: 50px;
                    ">Your responses have been recorded.</p>
                </div>
                
                {% comment %} <button onclick="window.close()" style="
                    background: #f44336;
                    color: white;
                    border: none;
                    padding: 18px 40px;
                    border-radius: 50px;
                    font-size: 20px;
                    cursor: pointer;
                    transition: all 0.3s ease;
                    margin-top: 30px;
                " onmouseover="this.style.transform='scale(1.05)'" 
                   onmouseout="this.style.transform='scale(1)'">
                    üìû Close Interview
                </button> {% endcomment %}
            </div>
        `;
      
        
        return;
    }
    
    timeLeft--;
}

// Initialize everything
document.addEventListener('DOMContentLoaded', async function() {
    log('=== INITIALIZING INTERVIEW SYSTEM ===');
    
    // Initialize camera first
    const cameraSuccess = await initCamera();
    if (!cameraSuccess) {
        log('Camera initialization failed - cannot proceed');
        return;
    }
    
    log('Camera initialization complete');
    
    // Initialize speech recognition
    const speechSuccess = initSpeech();
    if (!speechSuccess) {
        log('Speech recognition initialization failed - cannot proceed');
        return;
    }
    
    // Initialize Whisper recording if needed
    if (window.useWhisperASR) {
        const whisperSuccess = initWhisperRecording();
        if (!whisperSuccess) {
            log('Whisper recording initialization failed');
        } else {
            log('Whisper ASR mode enabled');
        }
    }
    
    log('Speech recognition initialized');
    
    // Start timer
    setInterval(updateTimer, 1000);
    
    // Show initial question after delay
    setTimeout(() => {
        log('=== SHOWING INITIAL QUESTION ===');
        const question = TEMPLATE_DATA.initialQuestion || "Welcome to your AI interview! Please tell me about yourself.";
        const audioUrl = TEMPLATE_DATA.initialAudio || null;
        const duration = TEMPLATE_DATA.initialDuration || 5;
        
        isInitialized = true;
        showCurrentQuestion(question, audioUrl, duration);
    }, 2000);
    
    log('System initialization complete');
    
    // Force face tracking start after camera is ready
    setTimeout(() => {
        if (!window.globalFaceTracker) {
            const video = document.getElementById('userVideo');
            if (video) {
                console.log('üéØ Force starting face tracking');
                window.globalFaceTracker = new FaceTracker(video);
                window.globalFaceTracker.start();
            }
        }
    }, 5000);
    
    // Initialize face tracking directly
    setTimeout(() => {
        const video = document.getElementById('userVideo');
        if (video) {
            console.log('üéØ Starting face tracking on userVideo');
            window.globalFaceTracker = new FaceTracker(video);
            window.globalFaceTracker.start();
        }
    }, 2000);
    
    // Keep trying to start face tracking
    const startFaceTracking = () => {
        if (!window.globalFaceTracker) {
            const video = document.getElementById('userVideo');
            if (video && video.videoWidth > 0) {
                console.log('üéØ Face tracking auto-start');
                window.globalFaceTracker = new FaceTracker(video);
                window.globalFaceTracker.start();
            } else {
                setTimeout(startFaceTracking, 1000);
            }
        }
    };
    startFaceTracking();
});
    </script>
</body>
</html>