{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interview - {{ candidate_name }}</title>
    <style>
        body {
            background: #202124 !important;
            color: white !important;
            font-family: 'Google Sans', Roboto, Arial, sans-serif;
            margin: 0;
            padding: 0;
            height: 100vh;
            overflow: hidden;
        }
        html {
            background: #202124 !important;
        }
        .container {
            width: 100%;
            height: 100vh;
            display: flex;
            flex-direction: column;
            position: relative;
        }
        .header {
            position: absolute;
            top: 16px;
            left: 24px;
            z-index: 100;
        }
        .header h1 {
            font-size: 18px;
            font-weight: 400;
            margin: 0;
            color: #e8eaed;
        }
        .video-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 8px;
            width: 100%;
            height: calc(100vh - 120px);
            padding: 16px;
            background: #202124;
        }
        .video-box {
            position: relative;
            border-radius: 8px;
            overflow: hidden;
            background: #3c4043;
            border: 2px solid transparent;
        }
        .video-box.speaking {
            border-color: #34a853;
        }
        .ai-placeholder {
            width: 100%;
            height: 100%;
            background: #3c4043;
            display: flex;
            align-items: center;
            justify-content: center;
            flex-direction: column;
        }
        .ai-avatar {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background: #1a73e8;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 16px;
        }
        .ai-avatar-icon {
            font-size: 48px;
            color: white;
        }
        .ai-name {
            color: #e8eaed;
            font-size: 16px;
            font-weight: 400;
        }
        video {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1);
        }
        .participant-name {
            position: absolute;
            bottom: 12px;
            left: 12px;
            background: rgba(0,0,0,0.7);
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 14px;
            font-weight: 400;
            color: white;
        }
        .recording-indicator {
            position: absolute;
            top: 12px;
            left: 12px;
            background: #ea4335;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 12px;
            font-weight: 500;
            color: white;
            display: flex;
            align-items: center;
            gap: 4px;
        }
        .recording-dot {
            width: 6px;
            height: 6px;
            background: white;
            border-radius: 50%;
            animation: blink-recording 1.5s ease-in-out infinite;
        }
        .face-detection-status {
            position: absolute;
            bottom: 12px;
            right: 12px;
            background: rgba(234, 67, 53, 0.9);
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 12px;
            font-weight: 400;
            color: white;
            display: flex;
            align-items: center;
            gap: 4px;
            transition: all 0.2s ease;
        }
        .face-detection-status .status-dot {
            width: 6px;
            height: 6px;
            background: #ea4335;
            border-radius: 50%;
            animation: blink-status 2s ease-in-out infinite;
        }
        .face-detection-status.active {
            background: rgba(52, 168, 83, 0.9);
        }
        .face-detection-status.active .status-dot {
            background: #34a853;
        }
        .controls {
            position: fixed;
            bottom: 24px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 16px;
            align-items: center;
            background: rgba(60, 64, 67, 0.9);
            padding: 12px 24px;
            border-radius: 32px;
            z-index: 100;
        }
        .btn {
            background: #3c4043;
            color: white;
            border: none;
            padding: 12px;
            border-radius: 50%;
            font-size: 20px;
            cursor: pointer;
            transition: all 0.2s ease;
            width: 48px;
            height: 48px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .btn:hover {
            background: #5f6368;
        }
        .btn.end-call {
            background: #ea4335;
            padding: 12px 24px;
            border-radius: 24px;
            width: auto;
            font-size: 14px;
            font-weight: 500;
        }
        .transcript-section {
            position: fixed;
            bottom: 100px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(60, 64, 67, 0.9);
            padding: 16px 24px;
            border-radius: 8px;
            max-width: 600px;
            min-height: 48px;
            display: flex;
            align-items: center;
            justify-content: center;
            z-index: 99;
        }
        .conversation-text {
            color: white;
            font-size: 16px;
            line-height: 1.4;
            text-align: center;
            font-weight: 400;
        }
        .audio-status {
            position: fixed;
            top: 30px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(26, 115, 232, 0.9);
            color: white;
            padding: 12px 24px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: 500;
            z-index: 1000;
            display: none;
        }
        .audio-status.playing {
            display: block;
            background: #ff9800;
        }
        .audio-status.listening {
            display: block;
            background: #4caf50;
        }
        @keyframes blink-recording {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
        @keyframes blink-status {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="audio-status" id="audioStatus"></div>

        <div class="header">
            <h1>Interview Session for {{ candidate_name }}</h1>
        </div>

        <!-- Timer in top-right -->
        <div style="position: absolute; top: 24px; right: 24px; background: rgba(0,0,0,0.7); padding: 8px 12px; border-radius: 4px; font-size: 14px; z-index: 100; color: white;">
            <span id="timer">{{ interview.interview_duration_minutes|default:"15" }}:00</span>
        </div>
        
        <div class="video-grid">
            <!-- AI Interviewer -->
            <div class="video-box" id="aiVideoBox">
                <div class="ai-placeholder">
                    <div class="ai-avatar" id="aiAvatar">
                        <div class="ai-avatar-icon">ü§ñ</div>
                    </div>
                    <div class="ai-name">Sarah - AI Interviewer</div>
                </div>
                <div class="participant-name">Sarah - AI Interviewer</div>
            </div>
            
            <!-- User Video -->
            <div class="video-box" id="candidateVideoBox">
                <video id="userVideo" autoplay muted playsinline></video>
                
                <div class="recording-indicator">
                    <div class="recording-dot"></div>
                    <span>REC</span>
                </div>
                
                <div class="participant-name">{{ candidate_name|default:"You" }}</div>
                
                <div class="face-detection-status" id="faceStatus">
                    <div class="status-dot"></div>
                    <span>Face Detection: OFF</span>
                </div>
            </div>
        </div>
        
        <div class="controls">
            <button class="btn mic" id="micBtn" onclick="toggleMic()" title="Microphone">üé§</button>
            <button class="btn" onclick="startFaceDetection()" title="Face Detection">üëÅÔ∏è</button>
            <button class="btn end-call" onclick="endInterview()">End Interview</button>
        </div>

        <div class="transcript-section">
            <div class="conversation-text" id="conversationArea"></div>
        </div>
    </div>

    <audio id="aiAudio" preload="auto"></audio>
    {% csrf_token %}
    <script src="{% static 'js/typewriter-sync.js' %}"></script>
    <script src="{% static 'js/face-tracking.js' %}"></script>
    
    <!-- Real-time Voice Agent Integration -->
    {% include 'jobapp/voice_agent_widget.html' %}

    <script>
    const TEMPLATE_DATA = {
        initialQuestion: `{{ ai_question|escapejs|default:"Welcome to your AI interview! Let's begin." }}`,
        initialAudio: `{{ audio_url|escapejs|safe }}`,
        initialDuration: {{ audio_duration|default:5 }},
        candidateName: `{{ candidate_name|escapejs|default:"Candidate" }}`,
        interviewUuid: `{{ interview.uuid|default:"" }}`,
        hasAudio: {{ has_audio|yesno:"true,false" }},
        csrfToken: `{{ csrf_token }}`
    };

    let recognition = null;
    let isListening = false;
    let questionCount = 1;
    let timeLeft = {{ interview.interview_duration_minutes|default:"15" }} * 60;
    let userStream = null;
    let collectedText = '';
    let speechTimeout = null;
    let isProcessingResponse = false;
    let isInterviewerSpeaking = false;
    let interviewCompleted = false;
    let audioEndedTimeout = null;
    let screenshots = [];
    let screenshotInterval = null;

    const conversationArea = document.getElementById('conversationArea');
    const audioStatus = document.getElementById('audioStatus');
    const micBtn = document.getElementById('micBtn');

    function log(message) {
        console.log(`[${new Date().toLocaleTimeString()}] ${message}`);
    }

    async function initCamera() {
        try {
            userStream = await navigator.mediaDevices.getUserMedia({ 
                video: { width: { ideal: 1280 }, height: { ideal: 720 }, facingMode: 'user' }, 
                audio: { echoCancellation: true, noiseSuppression: false, autoGainControl: false }
            });
            document.getElementById('userVideo').srcObject = userStream;
            startScreenshotCapture();
            return true;
        } catch (error) {
            conversationArea.innerHTML = `<div style="color: #f44336;">Please allow camera and microphone access, then refresh.</div>`;
            return false;
        }
    }
    
    function captureScreenshot(reason = 'scheduled') {
        const video = document.getElementById('userVideo');
        if (!video || video.videoWidth === 0) return;
        
        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const ctx = canvas.getContext('2d');
        ctx.drawImage(video, 0, 0);
        
        const imageData = canvas.toDataURL('image/jpeg', 0.8);
        screenshots.push({
            timestamp: new Date().toISOString(),
            image: imageData,
            reason: reason
        });
        
        console.log(`Screenshot captured (${reason}): ${screenshots.length}`);
        
        // Send immediate screenshot for second person detection
        if (reason === 'second_person_detected') {
            sendScreenshotToServer(imageData, reason);
        }
    }
    
    function sendScreenshotToServer(imageData, reason) {
        fetch('/interview/screenshot/', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'X-CSRFToken': TEMPLATE_DATA.csrfToken
            },
            body: JSON.stringify({
                screenshot: imageData,
                interview_id: TEMPLATE_DATA.interviewUuid,
                timestamp: new Date().toISOString(),
                reason: reason
            })
        }).then(response => {
            if (response.ok) {
                console.log(`Screenshot sent to server: ${reason}`);
            }
        }).catch(error => {
            console.error('Failed to send screenshot:', error);
        });
    }
    
    // Make captureScreenshot globally available
    window.captureScreenshot = captureScreenshot;
    
    function startScreenshotCapture() {
        screenshotInterval = setInterval(() => captureScreenshot('scheduled'), 10000); // Every 10 seconds
    }
    
    function stopScreenshotCapture() {
        if (screenshotInterval) {
            clearInterval(screenshotInterval);
            screenshotInterval = null;
        }
    }

    function initSpeech() {
        if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
            window.useWhisperASR = true;
            return true;
        }
        
        const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
        recognition = new SpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';
        
        recognition.onstart = () => {
            isListening = true;
            micBtn.classList.add('recording');
            document.getElementById('candidateVideoBox').classList.add('speaking');
        };
        
        recognition.onend = () => {
            document.getElementById('candidateVideoBox').classList.remove('speaking');
            if (isListening && !interviewCompleted && !isInterviewerSpeaking) {
                setTimeout(() => recognition && isListening && recognition.start(), 100);
            }
        };
        
        recognition.onresult = (event) => {
            let finalTranscript = '';
            for (let i = event.resultIndex; i < event.results.length; i++) {
                if (event.results[i].isFinal) {
                    finalTranscript += event.results[i][0].transcript;
                }
            }
            
            if (finalTranscript.trim() && !isInterviewerSpeaking && !isProcessingResponse) {
                collectedText += finalTranscript;
                if (speechTimeout) clearTimeout(speechTimeout);
                speechTimeout = setTimeout(() => {
                    if (collectedText.trim()) autoSubmitResponse();
                }, 3000);
            }
        };
        
        return true;
    }

    function startMicrophone() {
        if (recognition && !isListening && !interviewCompleted && !isInterviewerSpeaking) {
            try {
                isListening = true;
                recognition.start();
            } catch (e) {
                if (e.name === 'InvalidStateError') isListening = true;
            }
        }
    }

    function stopMicrophone() {
        if (recognition && isListening) {
            recognition.stop();
            isListening = false;
        }
    }

    function autoSubmitResponse() {
        if (isProcessingResponse || !collectedText.trim()) return;
        
        isProcessingResponse = true;
        const responseText = collectedText.trim();
        collectedText = '';
        stopMicrophone();
        
        conversationArea.innerHTML = '<div style="opacity: 0.7;">Processing...</div>';
        sendResponse(responseText).finally(() => isProcessingResponse = false);
    }

    async function sendResponse(text) {
        try {
            const formData = new FormData();
            formData.append('text', text);
            formData.append('time_remaining', timeLeft);
            formData.append('screenshots', JSON.stringify(screenshots));
            
            const response = await fetch(window.location.href, {
                method: 'POST',
                headers: { 'X-CSRFToken': TEMPLATE_DATA.csrfToken },
                body: formData
            });
            
            const data = await response.json();
            if (data.success) {
                setTimeout(() => showCurrentQuestion(data.response, data.audio, data.audio_duration), 100);
                if (data.interview_completed) {
                    interviewCompleted = true;
                    stopScreenshotCapture();
                }
            }
        } catch (error) {
            conversationArea.innerHTML = '<div style="color: #f44336;">Network error. Please try again.</div>';
            enableCandidateResponse();
        }
    }

    function showCurrentQuestion(question, audioUrl = null, audioDuration = null) {
        conversationArea.innerHTML = '';
        isProcessingResponse = true;
        isInterviewerSpeaking = true;
        stopMicrophone();
        
        document.getElementById('aiVideoBox').classList.add('speaking');
        
        if (audioUrl && audioDuration > 0) {
            audioStatus.className = 'audio-status playing';
            audioStatus.textContent = 'Interviewer speaking';
            audioStatus.style.display = 'block';
            
            const audio = document.getElementById('aiAudio');
            audio.src = audioUrl.startsWith('/media/') ? audioUrl : `/media/${audioUrl}`;
            audio.play().then(() => {
                startFallbackTypewriter(conversationArea, question, audioDuration);
            });
            
            audio.onended = () => setTimeout(() => enableCandidateResponse(), 1000);
        } else {
            startFallbackTypewriter(conversationArea, question);
        }
    }

    function startFallbackTypewriter(element, question, audioDuration = null) {
        let index = 0;
        const charDelay = audioDuration ? (audioDuration * 1000) / question.length : 50;
        
        const typeChar = () => {
            if (index < question.length) {
                element.textContent += question.charAt(index);
                index++;
                setTimeout(typeChar, charDelay);
            } else if (!audioDuration) {
                setTimeout(() => enableCandidateResponse(), 1000);
            }
        };
        typeChar();
    }

    function enableCandidateResponse() {
        isInterviewerSpeaking = false;
        isProcessingResponse = false;
        document.getElementById('aiVideoBox').classList.remove('speaking');
        
        audioStatus.className = 'audio-status listening';
        audioStatus.textContent = 'üé§ Your turn';
        audioStatus.style.display = 'block';
        setTimeout(() => audioStatus.style.display = 'none', 3000);
        
        collectedText = '';
        setTimeout(() => !interviewCompleted && startMicrophone(), 100);
    }

    function toggleMic() {
        if (interviewCompleted || isInterviewerSpeaking) return;
        
        if (isListening) {
            stopMicrophone();
            if (collectedText.trim()) autoSubmitResponse();
        } else {
            collectedText = '';
            startMicrophone();
        }
    }

    function startFaceDetection() {
        const video = document.getElementById('userVideo');
        if (video && video.videoWidth > 0) {
            window.globalFaceTracker = new FaceTracker(video);
            window.globalFaceTracker.start();
        }
    }

    function endInterview() {
        if (confirm('End interview?')) {
            interviewCompleted = true;
            stopScreenshotCapture();
            
            // Send final screenshots
            if (screenshots.length > 0) {
                fetch(window.location.href, {
                    method: 'POST',
                    headers: { 'X-CSRFToken': TEMPLATE_DATA.csrfToken },
                    body: new FormData().append('final_screenshots', JSON.stringify(screenshots))
                });
            }
            
            if (userStream) userStream.getTracks().forEach(track => track.stop());
            document.body.innerHTML = '<div style="display:flex;align-items:center;justify-content:center;height:100vh;background:#202124;color:white;font-size:24px;">Interview Ended</div>';
        }
    }

    function updateTimer() {
        if (interviewCompleted) return;
        const minutes = Math.floor(timeLeft / 60);
        const seconds = timeLeft % 60;
        document.getElementById('timer').textContent = `${minutes}:${seconds.toString().padStart(2, '0')}`;
        if (timeLeft <= 0) endInterview();
        timeLeft--;
    }

    document.addEventListener('DOMContentLoaded', async function() {
        const cameraSuccess = await initCamera();
        if (!cameraSuccess) return;
        
        initSpeech();
        setInterval(updateTimer, 1000);
        
        setTimeout(() => {
            const question = TEMPLATE_DATA.initialQuestion || "Welcome to your AI interview!";
            showCurrentQuestion(question, TEMPLATE_DATA.initialAudio, TEMPLATE_DATA.initialDuration);
        }, 2000);
        
        // Start face tracking
        setTimeout(() => {
            const video = document.getElementById('userVideo');
            if (video) {
                window.globalFaceTracker = new FaceTracker(video);
                window.globalFaceTracker.start();
            }
        }, 3000);
    });
    </script>
</body>
</html>